#!/bin/bash

# The MIT License (MIT)
#
# Copyright (c) 2022-present David G. Simmons
#
# Permission is hereby granted, free of charge, to any person obtaining a copy
# of this software and associated documentation files (the "Software"), to deal
# in the Software without restriction, including without limitation the rights
# to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
# copies of the Software, and to permit persons to whom the Software is
# furnished to do so, subject to the following conditions:
#
# The above copyright notice and this permission notice shall be included in all
# copies or substantial portions of the Software.
#
# THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
# IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
# FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
# AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
# LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
# OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
# SOFTWARE.
#


# Events Manager - Production-Ready Deployment Script
# Supports both dev and prod environments with .env configuration
# Usage: ./deploy.sh --dev OR ./deploy.sh --prod

set -e

# Colors for output
RED='\033[0;31m'
GREEN='\033[0;32m'
YELLOW='\033[1;33m'
BLUE='\033[0;34m'
NC='\033[0m' # No Color

# Function to print colored output
print_status() {
    echo -e "${BLUE}ğŸ”§ $1${NC}"
}

print_success() {
    echo -e "${GREEN}âœ… $1${NC}"
}

print_warning() {
    echo -e "${YELLOW}âš ï¸  $1${NC}"
}

print_error() {
    echo -e "${RED}âŒ $1${NC}"
}

print_info() {
    echo -e "${BLUE}â„¹ï¸  $1${NC}"
}

# Function to show usage
show_usage() {
    echo "Usage: $0 [--dev|--prod|--local|--gke|--eks] [options]"
    echo ""
    echo "Options:"
    echo "  --dev          Deploy to development environment (OpenShift)"
    echo "  --prod         Deploy to production environment (OpenShift)"
    echo "  --local        Deploy to local KIND cluster"
    echo "  --gke          Deploy to Google Kubernetes Engine (GKE)"
    echo "  --eks          Deploy to Amazon Elastic Kubernetes Service (EKS)"
    echo "  --help         Show this help message"
    echo "  --app          Deploy the application"
    echo "  --postgres     Deploy the postgres pod"
    echo "  --keycloak     Deploy the keycloak pod"
    echo "  --minio        Deploy the minio pod (local only)"
    echo "  --routes       Create routes for the application"
    echo "  --force        Force rebuild even if version hasn't changed"
    # echo "  --ai-only      Deploy only the AI (Ollama) service"
    echo "  --delete       Delete all pods while preserving data (WARNING: destructive)"
    echo "  --delete-local Delete local KIND cluster and all data (local only)"
    echo "  --backup       Create a complete backup of all data (users, events, uploads)"
    echo "  --restore -f   Restore data from backup directory (use with -f /path/to/backup)"
    echo "  --destroy      DESTROY ALL DATA - Remove pods and all PVCs (CATASTROPHIC)"
    echo ""
    echo "Requirements:"
    echo "  - For --dev/--prod: .env file must exist, OpenShift CLI (oc) installed"
    echo "  - For --local: .env.local file must exist, kubectl, kind, and podman installed"
    echo "  - For --gke: .env file must exist, gcloud CLI and kubectl installed"
    echo "  - For --eks: .env file must exist, aws CLI and kubectl installed"
    echo ""
    echo "Example:"
    echo "  $0 --dev"
    echo "  $0 --prod"
    echo "  $0 --local"
    echo "  $0 --gke"
    echo "  $0 --eks"
    echo "  $0 --delete-local"
    echo "  $0 --dev --app --postgres"
    echo "  $0 --local --postgres --keycloak --minio"
    echo "  $0 --prod --app --postgres --keycloak"
    echo "  $0 --gke --app --postgres --keycloak"
    echo "  $0 --eks --app --postgres --keycloak"
}

# Parse command line arguments
APP=""
KEYCLOAK=""
POSTGRES=""
MINIO=""
# AI=""
DELETE=""
DELETE_LOCAL=""
BACKUP=""
RESTORE=""
RESTORE_PATH=""
DESTROY=""
ENVIRONMENT=""
ROUTES=""
FORCE_BUILD=""
while [[ $# -gt 0 ]]; do
    case $1 in
        --dev)
            ENVIRONMENT="dev"
            shift
            ;;
        --prod)
            ENVIRONMENT="prod"
            shift
            ;;
        --local)
            ENVIRONMENT="local"
            shift
            ;;
        --gke)
            ENVIRONMENT="gke"
            shift
            ;;
        --eks)
            ENVIRONMENT="eks"
            shift
            ;;
        --help)
            show_usage
            exit 0
            ;;
        --app)
            APP="true"
            shift
            ;;
        --keycloak)
            KEYCLOAK="true"
            shift
            ;;
        --postgres)
            POSTGRES="true"
            shift
            ;;
        --minio)
            MINIO="true"
            shift
            ;;
        --routes)
            ROUTES="true"
            shift
            ;;
        # --ai-only)
        #     AI="true"
        #     shift
        #     ;;
        --force)
            FORCE_BUILD="true"
            shift
            ;;
        --delete)
            DELETE="true"
            shift
            ;;
        --delete-local)
            DELETE_LOCAL="true"
            shift
            ;;
        --backup)
            BACKUP="true"
            shift
            ;;
        --restore)
            RESTORE="true"
            shift
            ;;
        -f)
            if [[ "$RESTORE" == "true" ]]; then
                RESTORE_PATH="$2"
                shift 2
            else
                print_error "Option -f can only be used with --restore"
                exit 1
            fi
            ;;
        --destroy)
            DESTROY="true"
            shift
            ;;
        *)
            print_error "Unknown option: $1"
            show_usage
            exit 1
            ;;
    esac
done

# Validate arguments (skip for operations that don't need environment)
if [[ "$DELETE" != "true" && "$DELETE_LOCAL" != "true" && "$BACKUP" != "true" && "$RESTORE" != "true" && "$DESTROY" != "true" && -z "$ENVIRONMENT" ]]; then
    print_error "ğŸš¨ Environment not specified. Use --dev, --prod, --local, --gke, or --eks"
    show_usage
    exit 1
fi

# Validate restore path if restore is specified
if [[ "$RESTORE" == "true" && -z "$RESTORE_PATH" ]]; then
    print_error "ğŸš¨ Restore path must be specified with -f option"
    show_usage
    exit 1
fi

# Skip environment loading for operations that don't need it
# Note: BACKUP and RESTORE need environment variables, so we load them
if [[ "$DELETE_LOCAL" != "true" && "$DELETE" != "true" && "$BACKUP" != "true" && "$RESTORE" != "true" && "$DESTROY" != "true" ]]; then
    # Check for appropriate .env file based on environment
    if [[ "$ENVIRONMENT" == "local" ]]; then
        if [[ ! -f .env.local ]]; then
            print_error "ğŸš¨ .env.local file not found!"
            echo "ğŸš¨ Please run the configuration script to create .env.local:"
            echo "ğŸš¨   ./configure.sh --local"
            echo "ğŸš¨ Or manually copy env.local.template to .env.local:"
            echo "ğŸš¨   cp env.local.template .env.local"
            exit 1
        fi
        ENV_FILE=".env.local"
    else
        if [[ ! -f .env ]]; then
            print_error "ğŸš¨ .env file not found!"
            echo "ğŸš¨ Please copy env.template to .env and configure your values:"
            echo "ğŸš¨   cp env.template .env"
            echo "ğŸš¨   # Edit .env with your configuration"
            exit 1
        fi
        ENV_FILE=".env"
    fi

    # Load environment variables
    print_status "Loading configuration from $ENV_FILE file..."
    set -a  # automatically export all variables
    source "$ENV_FILE"
    set +a  # turn off automatic export
elif [[ "$BACKUP" == "true" || "$RESTORE" == "true" ]]; then
    # Backup and restore operations need environment variables
    if [[ "$ENVIRONMENT" == "local" ]]; then
        if [[ ! -f .env.local ]]; then
            print_error "ğŸš¨ .env.local file not found!"
            exit 1
        fi
        ENV_FILE=".env.local"
    else
        if [[ ! -f .env ]]; then
            print_error "ğŸš¨ .env file not found!"
            exit 1
        fi
        ENV_FILE=".env"
    fi

    # Load environment variables
    print_status "Loading configuration from $ENV_FILE file..."
    set -a  # automatically export all variables
    source "$ENV_FILE"
    set +a  # turn off automatic export
fi

# Set environment-specific variables (skip for standalone operations)
# Note: BACKUP and RESTORE need NAMESPACE and other env-specific vars
if [[ "$DELETE_LOCAL" != "true" && "$DELETE" != "true" && "$BACKUP" != "true" && "$RESTORE" != "true" && "$DESTROY" != "true" ]]; then
    if [[ "$ENVIRONMENT" == "local" ]]; then
        export NAMESPACE="ospo-local"
        export APP_URL="http://localhost:4576"
        export KEYCLOAK_URL="http://localhost:8080/auth"
        export VITE_KEYCLOAK_URL="http://localhost:8080/auth"
        export CLUSTER_NAME="ospo-local"
        export CLI_CMD="kubectl"
        export PLATFORM="kubernetes"
    elif [[ "$ENVIRONMENT" == "gke" ]]; then
        export NAMESPACE="${GKE_NAMESPACE:-ospo-events}"
        export APP_URL="${GKE_APP_URL}"
        export KEYCLOAK_URL="${GKE_KEYCLOAK_URL}"
        export VITE_KEYCLOAK_URL="${GKE_KEYCLOAK_URL}"
        export CLI_CMD="kubectl"
        export PLATFORM="gke"
        # Set image registry defaults if not provided
        export IMAGE_REGISTRY="${IMAGE_REGISTRY:-gcr.io/${GKE_PROJECT_ID}}"
        export IMAGE_NAME="${IMAGE_NAME:-ospo-events-app}"
        export IMAGE_TAG="${IMAGE_TAG:-latest}"
    elif [[ "$ENVIRONMENT" == "eks" ]]; then
        export NAMESPACE="${EKS_NAMESPACE:-ospo-events}"
        export APP_URL="${EKS_APP_URL}"
        export KEYCLOAK_URL="${EKS_KEYCLOAK_URL}"
        export VITE_KEYCLOAK_URL="${EKS_KEYCLOAK_URL}"
        export CLI_CMD="kubectl"
        export PLATFORM="eks"
        # Set image registry defaults if not provided
        export IMAGE_REGISTRY="${IMAGE_REGISTRY:-${AWS_ACCOUNT_ID}.dkr.ecr.${EKS_REGION}.amazonaws.com}"
        export IMAGE_NAME="${IMAGE_NAME:-ospo-events-app}"
        export IMAGE_TAG="${IMAGE_TAG:-latest}"
    elif [[ "$ENVIRONMENT" == "dev" ]]; then
        export NAMESPACE="$DEV_NAMESPACE"
        export APP_URL="$DEV_APP_URL"
        export KEYCLOAK_URL="$DEV_KEYCLOAK_URL"
        export VITE_KEYCLOAK_URL="$VITE_KEYCLOAK_URL_DEV"
        export CLI_CMD="oc"
        export PLATFORM="openshift"
        # OpenShift uses internal registry
        export IMAGE_REGISTRY="image-registry.openshift-image-registry.svc:5000/${DEV_NAMESPACE}"
        export IMAGE_NAME="ospo-events-app"
        export IMAGE_TAG="latest"
    else
        export NAMESPACE="$PROD_NAMESPACE"
        export APP_URL="$PROD_APP_URL"
        export KEYCLOAK_URL="$PROD_KEYCLOAK_URL"
        export VITE_KEYCLOAK_URL="$VITE_KEYCLOAK_URL_PROD"
        export CLI_CMD="oc"
        export PLATFORM="openshift"
        # OpenShift uses internal registry
        export IMAGE_REGISTRY="image-registry.openshift-image-registry.svc:5000/${PROD_NAMESPACE}"
        export IMAGE_NAME="ospo-events-app"
        export IMAGE_TAG="latest"
    fi

    # Export application configuration variables
    export UPLOADS_DIR="$UPLOADS_DIR"

    print_success "Configuration loaded for $ENVIRONMENT environment"
    print_status "Namespace: $NAMESPACE"
    print_status "App URL: $APP_URL"
    print_status "Keycloak URL: $KEYCLOAK_URL"
elif [[ "$BACKUP" == "true" || "$RESTORE" == "true" ]]; then
    # Set environment-specific variables for backup/restore operations
    if [[ "$ENVIRONMENT" == "local" ]]; then
        export NAMESPACE="ospo-local"
        export CLI_CMD="kubectl"
    elif [[ "$ENVIRONMENT" == "dev" ]]; then
        export NAMESPACE="$DEV_NAMESPACE"
        export CLI_CMD="oc"
    else
        export NAMESPACE="$PROD_NAMESPACE"
        export CLI_CMD="oc"
    fi

    print_success "Configuration loaded for $ENVIRONMENT environment"
    print_status "Namespace: $NAMESPACE"
fi

# =============================================================================
# KIND CLUSTER FUNCTIONS (Local Development)
# =============================================================================

# Function to setup KIND cluster
setup_kind_cluster() {
    print_status "Creating KIND cluster '${CLUSTER_NAME}'..."

    # Configure Podman to use only its own configuration (ignore Docker config entirely)
    # Note: This project uses Podman exclusively for local development, so Docker config files are ignored
    export REGISTRY_AUTH_FILE="${HOME}/.config/containers/auth.json"
    export CONTAINERS_AUTH_FILE="${HOME}/.config/containers/auth.json"
    # Explicitly unset Docker config to ensure Podman doesn't try to use Docker's credential helpers
    unset DOCKER_CONFIG
    # Create Podman auth directory if it doesn't exist
    mkdir -p "${HOME}/.config/containers"

    # Create a minimal Podman auth file if it doesn't exist (empty JSON object)
    # This ensures Podman has its own auth file and won't try to use Docker's config
    if [[ ! -f "${HOME}/.config/containers/auth.json" ]]; then
        echo '{}' > "${HOME}/.config/containers/auth.json"
    fi

    # Create KIND cluster with Podman provider
    # Note: Podman is configured above to use only its own auth file, ignoring Docker config entirely
    cat <<EOF | KIND_EXPERIMENTAL_PROVIDER=podman kind create cluster --name "${CLUSTER_NAME}" --config=-
kind: Cluster
apiVersion: kind.x-k8s.io/v1alpha4
nodes:
  - role: control-plane
    extraPortMappings:
      # PostgreSQL
      - containerPort: 30432
        hostPort: 5432
        protocol: TCP
      # Keycloak
      - containerPort: 30080
        hostPort: 8080
        protocol: TCP
      # MinIO API
      - containerPort: 30900
        hostPort: 9000
        protocol: TCP
      # MinIO Console
      - containerPort: 30901
        hostPort: 9001
        protocol: TCP
EOF

    if [ $? -eq 0 ]; then
        print_success "KIND cluster created successfully"
    else
        print_error "Failed to create KIND cluster"
        exit 1
    fi

    # Wait for cluster to be ready
    print_status "Waiting for cluster to be ready..."
    kubectl wait --for=condition=Ready nodes --all --timeout=120s
    print_success "Cluster is ready"

    # Create namespace
    print_status "Creating namespace '${NAMESPACE}'..."
    kubectl apply -f kind/namespace.yaml
    print_success "Namespace created"

    # Create NodePort services for external access
    create_nodeport_services_local
}

# Function to create NodePort services for local KIND cluster
create_nodeport_services_local() {
    print_status "Creating NodePort services for external access..."

    cat <<EOF | kubectl apply -f -
---
apiVersion: v1
kind: Service
metadata:
  name: postgres-nodeport
  namespace: ${NAMESPACE}
spec:
  type: NodePort
  selector:
    app: postgres
  ports:
    - port: 5432
      targetPort: 5432
      nodePort: 30432
---
apiVersion: v1
kind: Service
metadata:
  name: keycloak-nodeport
  namespace: ${NAMESPACE}
spec:
  type: NodePort
  selector:
    app: keycloak
  ports:
    - port: 8080
      targetPort: 8080
      nodePort: 30080
---
apiVersion: v1
kind: Service
metadata:
  name: minio-nodeport-api
  namespace: ${NAMESPACE}
spec:
  type: NodePort
  selector:
    app: minio
  ports:
    - name: api
      port: 9000
      targetPort: 9000
      nodePort: 30900
---
apiVersion: v1
kind: Service
metadata:
  name: minio-nodeport-console
  namespace: ${NAMESPACE}
spec:
  type: NodePort
  selector:
    app: minio
  ports:
    - name: console
      port: 9001
      targetPort: 9001
      nodePort: 30901
EOF

    print_success "NodePort services created"
}

# Function to deploy PostgreSQL to local KIND cluster
deploy_postgres_local() {
    print_status "ğŸ“¦ Deploying PostgreSQL to local KIND cluster..."

    if [[ ! -f "kind/postgres.yaml" ]]; then
        print_error "PostgreSQL deployment file not found: kind/postgres.yaml"
        exit 1
    fi

    kubectl apply -f kind/postgres.yaml

    print_status "Waiting for PostgreSQL to be ready..."
    kubectl wait --for=condition=Ready pod -l app=postgres -n "${NAMESPACE}" --timeout=180s || {
        print_warning "PostgreSQL pod didn't become ready in time. Checking status..."
        kubectl get pods -n "${NAMESPACE}" -l app=postgres
        kubectl describe pod -n "${NAMESPACE}" -l app=postgres
    }

    print_success "PostgreSQL deployed successfully"
}

# Function to deploy Keycloak to local KIND cluster
deploy_keycloak_local() {
    print_status "ğŸ“¦ Deploying Keycloak to local KIND cluster..."

    # Load Keycloak realm configuration
    local realm_file="keycloak-realm-export.json"

    if [ -f "$realm_file" ]; then
        print_status "Loading Keycloak realm configuration..."
        kubectl create configmap keycloak-realm-config \
            --from-file=realm.json="$realm_file" \
            --namespace="${NAMESPACE}" \
            --dry-run=client -o yaml | kubectl apply -f -
        print_success "Keycloak realm configuration loaded"
    else
        print_warning "Keycloak realm export file not found"
        print_info "Creating empty configmap..."
        kubectl create configmap keycloak-realm-config \
            --from-literal=realm.json='{}' \
            --namespace="${NAMESPACE}" \
            --dry-run=client -o yaml | kubectl apply -f -
    fi

    if [[ ! -f "kind/keycloak.yaml" ]]; then
        print_error "Keycloak deployment file not found: kind/keycloak.yaml"
        exit 1
    fi

    kubectl apply -f kind/keycloak.yaml

    print_status "Waiting for Keycloak to be ready (this may take a few minutes)..."
    kubectl wait --for=condition=Ready pod -l app=keycloak -n "${NAMESPACE}" --timeout=300s || {
        print_warning "Keycloak pod didn't become ready in time. Checking status..."
        kubectl get pods -n "${NAMESPACE}" -l app=keycloak
        kubectl describe pod -n "${NAMESPACE}" -l app=keycloak
    }

    print_success "Keycloak deployed successfully"
}

# Function to deploy MinIO to local KIND cluster
deploy_minio_local() {
    print_status "ğŸ“¦ Deploying MinIO to local KIND cluster..."

    if [[ ! -f "kind/minio.yaml" ]]; then
        print_error "MinIO deployment file not found: kind/minio.yaml"
        exit 1
    fi

    kubectl apply -f kind/minio.yaml

    print_status "Waiting for MinIO to be ready..."
    kubectl wait --for=condition=Ready pod -l app=minio -n "${NAMESPACE}" --timeout=180s || {
        print_warning "MinIO pod didn't become ready in time. Checking status..."
        kubectl get pods -n "${NAMESPACE}" -l app=minio
        kubectl describe pod -n "${NAMESPACE}" -l app=minio
    }

    print_success "MinIO deployed successfully"
}

# Check CLI tool and connection based on environment (skip for standalone operations)
# Note: BACKUP and RESTORE need CLI connection for OpenShift operations
if [[ "$DELETE_LOCAL" != "true" && "$DELETE" != "true" && "$BACKUP" != "true" && "$RESTORE" != "true" && "$DESTROY" != "true" ]]; then
    if [[ "$ENVIRONMENT" == "local" ]]; then
        print_status "Checking local Kubernetes (KIND) prerequisites..."

        # Check for required tools
        if ! command -v kubectl &>/dev/null; then
            print_error "kubectl is required but not installed!"
            echo "Installation instructions:"
            echo "  brew install kubectl"
            exit 1
        fi

        if ! command -v kind &>/dev/null; then
            print_error "kind is required but not installed!"
            echo "Installation instructions:"
            echo "  brew install kind"
            exit 1
        fi

        if ! command -v podman &>/dev/null; then
            print_error "podman is required but not installed!"
            echo "Installation instructions:"
            echo "  brew install podman"
            exit 1
        fi

        # Check if Podman machine is running
        if ! podman machine list | grep -q "Currently running"; then
            print_warning "Podman machine is not running. Starting it now..."
            podman machine start || {
                print_error "Failed to start Podman machine"
                print_info "Try initializing Podman: podman machine init"
                exit 1
            }
            print_success "Podman machine started"
            sleep 5  # Give Podman a moment to stabilize
        fi

        # Check if KIND cluster exists
        if ! kind get clusters 2>/dev/null | grep -q "^${CLUSTER_NAME}$"; then
            print_warning "KIND cluster '${CLUSTER_NAME}' does not exist"
            print_info "Creating KIND cluster..."
            setup_kind_cluster
        else
            print_success "KIND cluster '${CLUSTER_NAME}' exists"
        fi

        # Switch context to KIND cluster
        kubectl config use-context "kind-${CLUSTER_NAME}" &>/dev/null || {
            print_error "Failed to switch to KIND cluster context"
            exit 1
        }

    elif [[ "$ENVIRONMENT" == "gke" ]]; then
        # GKE connection check
        print_status "Checking GKE connection..."

        if ! command -v gcloud &>/dev/null; then
            print_error "gcloud CLI is required but not installed!"
            echo "Installation instructions:"
            echo "  https://cloud.google.com/sdk/docs/install"
            exit 1
        fi

        if ! command -v kubectl &>/dev/null; then
            print_error "kubectl is required but not installed!"
            exit 1
        fi

        # Authenticate and get cluster credentials
        print_status "Authenticating to GKE cluster..."
        gcloud container clusters get-credentials "${GKE_CLUSTER_NAME}" \
            --region "${GKE_REGION}" \
            --project "${GKE_PROJECT_ID}" || {
            print_error "Failed to get GKE cluster credentials"
            exit 1
        }

        # Create namespace if it doesn't exist
        kubectl create namespace "${NAMESPACE}" --dry-run=client -o yaml | kubectl apply -f -

        # Set context to namespace
        kubectl config set-context --current --namespace="${NAMESPACE}"

    elif [[ "$ENVIRONMENT" == "eks" ]]; then
        # EKS connection check
        print_status "Checking EKS connection..."

        if ! command -v aws &>/dev/null; then
            print_error "AWS CLI is required but not installed!"
            echo "Installation instructions:"
            echo "  https://aws.amazon.com/cli/"
            exit 1
        fi

        if ! command -v kubectl &>/dev/null; then
            print_error "kubectl is required but not installed!"
            exit 1
        fi

        # Authenticate and get cluster credentials
        print_status "Authenticating to EKS cluster..."
        aws eks update-kubeconfig \
            --name "${EKS_CLUSTER_NAME}" \
            --region "${EKS_REGION}" || {
            print_error "Failed to get EKS cluster credentials"
            exit 1
        }

        # Create namespace if it doesn't exist
        kubectl create namespace "${NAMESPACE}" --dry-run=client -o yaml | kubectl apply -f -

        # Set context to namespace
        kubectl config set-context --current --namespace="${NAMESPACE}"

    else
        # OpenShift connection check
        print_status "Checking OpenShift connection..."
        if ! oc whoami &>/dev/null; then
            print_error "Not logged into OpenShift!"
            echo "Please login first:"
            echo "  oc login --token=\$OPENSHIFT_TOKEN --server=\$OPENSHIFT_SERVER"
            exit 1
        fi

        # Switch to correct namespace
        print_status "Switching to namespace: $NAMESPACE"
        oc project "$NAMESPACE" || {
            print_error "Failed to switch to namespace $NAMESPACE"
            print_warning "Make sure the namespace exists or create it with:"
            echo "  oc new-project $NAMESPACE"
            exit 1
        }
    fi

    print_success "ğŸš€ Starting Events deployment to $ENVIRONMENT environment"
    echo ""
elif [[ "$BACKUP" == "true" || "$RESTORE" == "true" ]]; then
    # For backup/restore operations, we need CLI connection for OpenShift
    if [[ "$ENVIRONMENT" != "local" ]]; then
        # OpenShift connection check
        print_status "Checking OpenShift connection..."
        if ! oc whoami &>/dev/null; then
            print_error "Not logged into OpenShift!"
            echo "Please login first:"
            echo "  oc login --token=\$OPENSHIFT_TOKEN --server=\$OPENSHIFT_SERVER"
            exit 1
        fi

        # Switch to correct namespace
        print_status "Switching to namespace: $NAMESPACE"
        oc project "$NAMESPACE" || {
            print_error "Failed to switch to namespace $NAMESPACE"
            print_warning "Make sure the namespace exists or create it with:"
            echo "  oc new-project $NAMESPACE"
            exit 1
        }
    fi
fi

# =============================================================================
# COMMON DEPLOYMENT FUNCTIONS
# =============================================================================

# Function to wait for deployment
wait_for_deployment() {
    local deployment_name=$1
    local timeout=${2:-300}
    if [[ "$APP" == "true" ]]; then
        print_status "ğŸš€ Skipping wait for $deployment_name to be ready..."
        return 0
    fi
    print_status "Waiting for $deployment_name to be ready..."
    if $CLI_CMD wait --for=condition=available deployment/"$deployment_name" --timeout="${timeout}s" -n "${NAMESPACE}"; then
        print_success "$deployment_name is ready"
    else
        print_error "$deployment_name failed to become ready within ${timeout} seconds"
        return 1
    fi
}

# Function to create Docker Hub secret
create_dockerhub_secret() {
    print_status "ğŸ” Creating Docker Hub secret..."

    # Check if Docker Hub credentials are provided
    if [[ -z "${DOCKERHUB_USERNAME:-}" || -z "${DOCKERHUB_TOKEN:-}" ]]; then
        print_warning "Docker Hub credentials not provided. Using public images (may hit rate limits)."
        return 0
    fi

    oc create secret docker-registry dockerhub-secret \
        --docker-server=docker.io \
        --docker-username="${DOCKERHUB_USERNAME}" \
        --docker-password="${DOCKERHUB_TOKEN}" \
        --docker-email="${DOCKERHUB_EMAIL:-noreply@example.com}" \
        --dry-run=client -o yaml | oc apply -f -

    # Link the secret to service accounts for builds and pods
    oc secrets link builder dockerhub-secret
    oc secrets link default dockerhub-secret

    # Add to imagePullSecrets for builder service account
    oc patch serviceaccount builder -p '{"imagePullSecrets":[{"name":"dockerhub-secret"}]}' || true

    print_success "Docker Hub secret created and linked to service accounts"
}

# SAFETY FUNCTION: Prevent destructive operations without explicit confirmation
safety_check() {
    local operation=$1
    local destructive_operations=("delete" "patch" "rollout" "scale" "override" "wipe" "clear" "remove")

    for op in "${destructive_operations[@]}"; do
        if [[ "$operation" == *"$op"* ]]; then
            print_error "ğŸš¨ SAFETY CHECK FAILED: Operation '$operation' contains destructive command '$op'"
            print_error "ğŸš¨ This script is designed to be SAFE and NON-DESTRUCTIVE"
            print_error "ğŸš¨ If you need to perform destructive operations, do them manually with explicit confirmation"
            exit 1
        fi
    done
}

# Function to get version from package.json
get_package_version() {
    if [[ ! -f "package.json" ]]; then
        print_error "ğŸš¨ package.json not found"
        return 1
    fi
    grep '"version"' package.json | head -1 | sed 's/.*"version"//' | sed 's/[",: ]//g'
}

# Function to get latest version from ImageStream tags
get_latest_image_version() {
    local imagestream=$1
    local tags=$(oc get imagestream "${imagestream}" -o jsonpath='{range .status.tags[*]}{.tag}{"\n"}{end}' 2>/dev/null || echo "")

    if [[ -z "$tags" ]]; then
        print_status "ğŸ” No tags found for imagestream $imagestream"
        echo ""
        return 0
    fi

    # Filter for version-like tags (e.g., 0.3.15), excluding 'latest'
    echo "$tags" | grep -oE '[0-9]+\.[0-9]+\.[0-9]+' | sort -V | tail -1
}

# Function to compare version strings (semantic versioning)
version_greater() {
    local version1=$1
    local version2=$2

    # If version2 is empty, version1 is greater
    [[ -z "$version2" ]] && return 0

    # Compare versions using sort -V (natural sort for version numbers)
    [ "$version1" != "$(echo -e "$version1\n$version2" | sort -V | head -1)" ]
}

# SAFETY FUNCTION: Prevent Keycloak realm override without explicit flag
keycloak_safety_check() {
    if [[ "${KEYCLOAK_OVERRIDE_REALM:-}" != "true" ]]; then
        print_warning "ğŸ”’ Keycloak realm import is DISABLED by default to prevent data loss"
        print_warning "ğŸ”’ To enable realm import (DANGEROUS - can delete users), set KEYCLOAK_OVERRIDE_REALM=true"
        print_warning "ğŸ”’ This script will NOT import realm configuration to preserve existing users"
        return 0
    else
        print_error "ğŸš¨ KEYCLOAK OVERRIDE ENABLED - This can DELETE ALL USERS!"
        print_error "ğŸš¨ Are you absolutely sure? This action cannot be undone."
        print_error "ğŸš¨ If you proceed, all Keycloak users will be lost."
        exit 1
    fi
}

# Function to create PostgreSQL deployment
deploy_postgres() {
    print_status "ğŸ“¦ Deploying PostgreSQL..."

    # Check if PostgreSQL deployment file exists
    if [[ ! -f "k8s/common/postgres-deployment.yaml" ]]; then
        print_error "PostgreSQL deployment file not found: k8s/common/postgres-deployment.yaml"
        exit 1
    fi

    # Apply PostgreSQL deployment
    envsubst < k8s/common/postgres-deployment.yaml | $CLI_CMD apply -f - -n "${NAMESPACE}"

    wait_for_deployment postgres

    print_status "ğŸ“¦ Initializing Keycloak database..."
    sleep 5  # Give PostgreSQL a moment to be fully ready

    # Create Keycloak database and user (platform-agnostic)
    $CLI_CMD exec deployment/postgres -n "${NAMESPACE}" -- psql -U ${POSTGRES_USER} -d postgres -c "CREATE USER ${KEYCLOAK_DB_USER} WITH PASSWORD '${KEYCLOAK_DB_PASSWORD}';" 2>/dev/null || true
    $CLI_CMD exec deployment/postgres -n "${NAMESPACE}" -- psql -U ${POSTGRES_USER} -d postgres -c "CREATE DATABASE ${KEYCLOAK_DB_NAME} OWNER ${KEYCLOAK_DB_USER};" 2>/dev/null || true

    print_success "PostgreSQL and Keycloak database initialized"
}

# Function to create Minio deployment
deploy_minio() {
    print_status "ğŸ“¦ Deploying Minio..."

    # Check if MinIO deployment file exists
    if [[ ! -f "k8s/common/minio-deployment.yaml" ]]; then
        print_error "MinIO deployment file not found: k8s/common/minio-deployment.yaml"
        exit 1
    fi

    # Apply MinIO deployment
    envsubst < k8s/common/minio-deployment.yaml | $CLI_CMD apply -f - -n "${NAMESPACE}"

    wait_for_deployment minio
}

# Function to create Keycloak realm configuration
create_keycloak_realm_config() {
    local keycloak_hostname=$(echo "$KEYCLOAK_URL" | sed 's|https://||' | sed 's|/.*||')
    local app_hostname=$(echo "$APP_URL" | sed 's|https://||')

    cat > /tmp/keycloak-realm.json <<EOF
{
  "id": "ospo-events",
  "realm": "ospo-events",
  "displayName": "Events",
  "enabled": true,
  "sslRequired": "external",
  "registrationAllowed": true,
  "loginWithEmailAllowed": true,
  "duplicateEmailsAllowed": false,
  "resetPasswordAllowed": true,
  "editUsernameAllowed": false,
  "bruteForceProtected": true,
  "clients": [
    {
      "id": "ospo-events-app",
      "clientId": "ospo-events-app",
      "name": "Events Application",
      "enabled": true,
      "clientAuthenticatorType": "client-secret",
      "redirectUris": [
        "${APP_URL}/*",
        "https://*.${CLUSTER_DOMAIN}/*"
      ],
      "webOrigins": [
        "${APP_URL}",
        "https://*.${CLUSTER_DOMAIN}"
      ],
      "publicClient": true,
      "directAccessGrantsEnabled": true,
      "serviceAccountsEnabled": false,
      "authorizationServicesEnabled": false,
      "standardFlowEnabled": true,
      "implicitFlowEnabled": false,
      "directGrantsOnly": false
    }
  ],
  "roles": {
    "realm": [
      {
        "name": "admin",
        "description": "Administrator role"
      },
      {
        "name": "user",
        "description": "Regular user role"
      }
    ]
  }
}
EOF

    # Create ConfigMap (platform-agnostic)
    if [[ "$PLATFORM" == "openshift" ]]; then
        oc create configmap keycloak-realm-config --from-file=realm.json=/tmp/keycloak-realm.json --dry-run=client -o yaml | oc apply -f -
    else
        kubectl create configmap keycloak-realm-config --from-file=realm.json=/tmp/keycloak-realm.json --dry-run=client -o yaml | kubectl apply -f - -n "${NAMESPACE}"
    fi
    rm -f /tmp/keycloak-realm.json
}

# Function to create Keycloak deployment
deploy_keycloak() {
    print_status "ğŸ“¦ Deploying Keycloak..."

    # SAFETY CHECK: Prevent realm import that could delete users
    keycloak_safety_check

    # Always create the realm config ConfigMap (required by deployment)
    # But only populate it with realm data if override is explicitly enabled
    if [[ "${KEYCLOAK_OVERRIDE_REALM:-}" == "true" ]]; then
        print_status "ğŸ”“ Creating realm configuration with realm data (OVERRIDE ENABLED)"
        create_keycloak_realm_config
    else
        print_warning "ğŸ”’ Creating empty realm configuration to preserve existing users"
        # Create an empty ConfigMap to satisfy the deployment requirement
        oc create configmap keycloak-realm-config --from-file=realm.json=keycloak-realm-export.json --dry-run=client -o yaml | oc apply -f -
    fi

    local keycloak_hostname=$(echo "$KEYCLOAK_URL" | sed 's|https://||' | sed 's|/.*||')

    # Check if Keycloak deployment file exists
    if [[ ! -f "k8s/common/keycloak-deployment.yaml" ]]; then
        print_error "Keycloak deployment file not found: k8s/common/keycloak-deployment.yaml"
        exit 1
    fi

    # Apply Keycloak deployment with environment variable substitution
    keycloak_hostname=$(echo "$KEYCLOAK_URL" | sed 's|https://||' | sed 's|/.*||')
    export keycloak_hostname
    envsubst < k8s/common/keycloak-deployment.yaml | $CLI_CMD apply -f - -n "${NAMESPACE}"

    wait_for_deployment keycloak 600  # Keycloak takes longer to start
}

# Function to build and push Docker image to external registry
build_and_push_image() {
    local current_version=$1
    local image_tag="${IMAGE_REGISTRY}/${IMAGE_NAME}:${IMAGE_TAG}"
    local versioned_tag="${IMAGE_REGISTRY}/${IMAGE_NAME}:${current_version}"

    print_status "ğŸ”¨ Building Docker image..."

    # Build the image
    docker build \
        --build-arg VITE_KEYCLOAK_URL="${VITE_KEYCLOAK_URL}" \
        --build-arg VERSION="${current_version}" \
        -t "${image_tag}" \
        -t "${versioned_tag}" \
        .

    if [ $? -ne 0 ]; then
        print_error "Failed to build Docker image"
        exit 1
    fi

    print_success "âœ… Docker image built successfully"

    # Authenticate to registry based on platform
    if [[ "$ENVIRONMENT" == "gke" ]]; then
        print_status "ğŸ” Authenticating to GCR..."
        gcloud auth configure-docker --quiet || {
            print_error "Failed to authenticate to GCR"
            exit 1
        }
    elif [[ "$ENVIRONMENT" == "eks" ]]; then
        print_status "ğŸ” Authenticating to ECR..."
        aws ecr get-login-password --region "${EKS_REGION}" | \
            docker login --username AWS --password-stdin "${IMAGE_REGISTRY}" || {
            print_error "Failed to authenticate to ECR"
            exit 1
        }
    else
        # Docker Hub authentication
        if [[ -n "${DOCKERHUB_USERNAME:-}" && -n "${DOCKERHUB_TOKEN:-}" ]]; then
            print_status "ğŸ” Authenticating to Docker Hub..."
            echo "${DOCKERHUB_TOKEN}" | docker login --username "${DOCKERHUB_USERNAME}" --password-stdin || {
                print_error "Failed to authenticate to Docker Hub"
                exit 1
            }
        fi
    fi

    # Push both tags
    print_status "ğŸ“¤ Pushing image ${image_tag}..."
    docker push "${image_tag}" || {
        print_error "Failed to push image ${image_tag}"
        exit 1
    }

    print_status "ğŸ“¤ Pushing image ${versioned_tag}..."
    docker push "${versioned_tag}" || {
        print_error "Failed to push image ${versioned_tag}"
        exit 1
    }

    print_success "âœ… Images pushed successfully: ${image_tag} and ${versioned_tag}"
}

# Function to create GKE Ingress
create_gke_ingress() {
    print_status "ğŸŒ Creating GKE Ingress..."

    if [[ ! -f "k8s/gke/ingress.yaml" ]]; then
        print_error "ğŸš¨ GKE Ingress file not found: k8s/gke/ingress.yaml"
        exit 1
    fi

    # Set hostname variables for substitution
    local keycloak_hostname=$(echo "$KEYCLOAK_URL" | sed 's|https://||' | sed 's|http://||' | sed 's|/.*||')
    local app_hostname=$(echo "$APP_URL" | sed 's|https://||' | sed 's|http://||' | sed 's|/.*||')
    export keycloak_hostname
    export app_hostname

    # Delete existing ingress if it exists
    kubectl delete ingress ospo-events-ingress --ignore-not-found=true -n "${NAMESPACE}"

    # Apply ingress with environment variable substitution
    envsubst < k8s/gke/ingress.yaml | kubectl apply -f -

    print_success "âœ… GKE Ingress created successfully"
}

# Function to create EKS Ingress
create_eks_ingress() {
    print_status "ğŸŒ Creating EKS Ingress..."

    if [[ ! -f "k8s/eks/ingress.yaml" ]]; then
        print_error "ğŸš¨ EKS Ingress file not found: k8s/eks/ingress.yaml"
        exit 1
    fi

    # Set hostname variables for substitution
    local keycloak_hostname=$(echo "$KEYCLOAK_URL" | sed 's|https://||' | sed 's|http://||' | sed 's|/.*||')
    local app_hostname=$(echo "$APP_URL" | sed 's|https://||' | sed 's|http://||' | sed 's|/.*||')
    export keycloak_hostname
    export app_hostname

    # Delete existing ingress if it exists
    kubectl delete ingress ospo-events-ingress --ignore-not-found=true -n "${NAMESPACE}"

    # Apply ingress with environment variable substitution
    envsubst < k8s/eks/ingress.yaml | kubectl apply -f -

    print_success "âœ… EKS Ingress created successfully"
}

# Function to create application build and deployment
deploy_app() {
    print_status "ğŸ“¦ Deploying Events Application..."

    # Get current version from package.json
    local current_version=$(get_package_version)
    print_status "ğŸ” Current version in package.json: $current_version"



    # Create keycloak.json configuration dynamically
    cat > /tmp/keycloak.json <<EOF
{
  "realm": "${KEYCLOAK_REALM}",
  "auth-server-url": "${KEYCLOAK_URL}/auth",
  "ssl-required": "external",
  "resource": "${KEYCLOAK_CLIENT_ID}",
  "public-client": true,
  "confidential-port": 0,
  "verify-token-audience": false,
  "use-resource-role-mappings": true,
  "enable-cors": true
}
EOF

    # Create ConfigMap for keycloak.json (platform-agnostic)
    if [[ "$PLATFORM" == "openshift" ]]; then
        oc create configmap keycloak-client-config --from-file=keycloak.json=/tmp/keycloak.json --dry-run=client -o yaml | oc apply -f -
    else
        kubectl create configmap keycloak-client-config --from-file=keycloak.json=/tmp/keycloak.json --dry-run=client -o yaml | kubectl apply -f - -n "${NAMESPACE}"
    fi
    rm -f /tmp/keycloak.json

    # Handle build process based on platform
    if [[ "$PLATFORM" == "openshift" ]]; then
        # OpenShift: Use BuildConfig and ImageStream
        # Ensure Docker Hub secret exists for builds
        if [[ $APP == "true" ]]; then
          create_dockerhub_secret
        fi

        # Create ImageStream
        if [[ ! -f "k8s/openshift/app-imagestream.yaml" ]]; then
            print_error "ğŸš¨ App ImageStream file not found: k8s/openshift/app-imagestream.yaml"
            exit 1
        fi
        oc apply -f k8s/openshift/app-imagestream.yaml

        # Create BuildConfig
        if [[ ! -f "k8s/openshift/app-buildconfig.yaml" ]]; then
            print_error "ğŸš¨ App BuildConfig file not found: k8s/openshift/app-buildconfig.yaml"
            exit 1
        fi

        # Export version for BuildConfig
        export APP_VERSION="$current_version"
        envsubst < k8s/openshift/app-buildconfig.yaml | oc apply -f -

        # Start build
        print_status "ğŸ”¨ Starting application build for version $current_version..."
        oc start-build ospo-events-app --from-dir=. --wait

        # Tag the image with the version number in addition to 'latest'
        print_status "ğŸ·ï¸  Tagging image as version $current_version..."
        oc tag ospo-events-app:latest ospo-events-app:"$current_version"

        print_success "âœ… Built and tagged as ospo-events-app:$current_version and ospo-events-app:latest"
    else
        # GKE/EKS/Local: Build and push to external registry
        # Check if build is needed (unless --force is specified)
        if [[ "$FORCE_BUILD" != "true" ]]; then
            # For external registries, we'll always build for now
            # TODO: Add version checking for external registries
            print_status "Building new version: $current_version"
        else
            print_status "Force build requested, skipping version check"
        fi

        # Build and push image
        build_and_push_image "$current_version"

        # Update IMAGE_TAG to use versioned tag
        export IMAGE_TAG="$current_version"
    fi

    # Create Deployment (use common manifest)
    if [[ ! -f "k8s/common/app-deployment.yaml" ]]; then
        print_error "ğŸš¨ App deployment file not found: k8s/common/app-deployment.yaml"
        exit 1
    fi
    envsubst < k8s/common/app-deployment.yaml | $CLI_CMD apply -f - -n "${NAMESPACE}"

    wait_for_deployment ospo-app
}

# Function to deploy AI (Ollama) service
deploy_ai() {
    print_status "ğŸ¤– Deploying AI (Ollama) Service..."

    # Check if Ollama deployment file exists
    if [[ ! -f "k8s/ollama-deployment.yaml" ]]; then
        print_error "ğŸš¨ Ollama deployment file not found: k8s/ollama-deployment.yaml"
        exit 1
    fi

    # Apply Ollama deployment
    oc apply -f k8s/ollama-deployment.yaml

    # Wait for deployment to be ready
    wait_for_deployment ollama-nvidia-gpu

    print_success "ğŸ¤– AI (Ollama) service deployed successfully!"

    # Show Ollama service information
    print_status "ğŸ“‹ Ollama Service Information:"
    echo "  - Service: ollama-nvidia-gpu"
    echo "  - Port: 11434"
    echo "  - GPU: NVIDIA GPU required"
    echo "  - Models: Will be downloaded on first use"

    # Show how to download models
    print_status "ğŸ“¥ To download models, you can:"
    echo "  1. Port forward: oc port-forward svc/ollama-nvidia-gpu 11434:11434"
    echo "  2. Pull model: ollama pull codellama:7b-instruct"
    echo "  3. Or use the internal service URL: http://ollama-nvidia-gpu:11434"
}

# Function to create routes/ingress based on platform
create_routes() {
    if [[ "$PLATFORM" == "openshift" ]]; then
        print_status "ğŸŒ Creating OpenShift Routes..."

        # Check if routes file exists
        if [[ ! -f "k8s/openshift/routes.yaml" ]]; then
            print_error "ğŸš¨ Routes file not found: k8s/openshift/routes.yaml"
            exit 1
        fi

        # Set hostname variables for substitution
        local keycloak_hostname=$(echo "$KEYCLOAK_URL" | sed 's|https://||')
        local app_hostname=$(echo "$APP_URL" | sed 's|https://||')
        export keycloak_hostname
        export app_hostname
        print_status "ğŸ” keycloak_hostname: $keycloak_hostname"
        print_status "ğŸ” app_hostname: $app_hostname"

        oc delete route ospo-app --ignore-not-found=true
        oc delete route keycloak --ignore-not-found=true
        # Apply routes with environment variable substitution
        envsubst < k8s/openshift/routes.yaml | oc apply -f -

        print_success "âœ… OpenShift Routes created successfully"
    elif [[ "$PLATFORM" == "gke" ]]; then
        create_gke_ingress
    elif [[ "$PLATFORM" == "eks" ]]; then
        create_eks_ingress
    else
        # Local/KIND: No ingress needed (uses NodePort)
        print_status "ğŸŒ Local deployment uses NodePort services - no ingress needed"
    fi
}

# Function to safely delete all pods while preserving data
delete_all_pods() {
    print_warning "âš ï¸  WARNING: This will delete ALL pods in the cluster!"
    print_warning "âš ï¸  This action will:"
    print_warning "   - Delete all running pods (ospo-app, keycloak, postgres, minio, ollama)"
    print_warning "   - Delete all deployments, services, and routes"
    print_warning "   - DELETE ALL DATA if PersistentVolumeClaims are removed"
    print_warning ""
    print_warning "âš ï¸  DATA PRESERVATION:"
    print_warning "   âœ… Keycloak user data will be preserved (stored in PostgreSQL PVC)"
    print_warning "   âœ… Event data will be preserved (stored in PostgreSQL PVC)"
    print_warning "   âœ… Uploaded files will be preserved (stored in MinIO PVC)"
    print_warning "   âœ… Application uploads will be preserved (stored in app PVC)"
    print_warning ""
    print_warning "âš ï¸  THIS ACTION CANNOT BE UNDONE!"
    echo ""

    # Require explicit confirmation
    read -p "Are you absolutely sure you want to delete all pods? Type 'DELETE ALL PODS' to confirm: " confirmation

    if [[ "$confirmation" != "DELETE ALL PODS" ]]; then
        print_error "ğŸš¨ Deletion cancelled. You must type 'DELETE ALL PODS' exactly to confirm."
        exit 1
    fi

    print_status "ğŸ—‘ï¸  Starting safe deletion of all pods..."

    # Delete deployments (this will delete pods)
    print_status "Deleting deployments..."
    oc delete deployment ospo-app --ignore-not-found=true
    oc delete deployment keycloak --ignore-not-found=true
    oc delete deployment postgres --ignore-not-found=true
    oc delete deployment minio --ignore-not-found=true
    oc delete deployment ollama-nvidia-gpu --ignore-not-found=true

    # Delete services
    print_status "Deleting services..."
    oc delete service ospo-app --ignore-not-found=true
    oc delete service keycloak --ignore-not-found=true
    oc delete service postgres --ignore-not-found=true
    oc delete service minio --ignore-not-found=true
    oc delete service ollama-nvidia-gpu --ignore-not-found=true

    # Delete routes
    print_status "Deleting routes..."
    oc delete route ospo-app --ignore-not-found=true
    oc delete route keycloak --ignore-not-found=true
    oc delete route ollama-nvidia-gpu --ignore-not-found=true

    # Delete configmaps
    print_status "Deleting configmaps..."
    oc delete configmap keycloak-client-config --ignore-not-found=true
    oc delete configmap keycloak-realm-config --ignore-not-found=true

    # Delete secrets (but preserve PVCs and ImageStreams)
    print_status "Deleting secrets..."
    oc delete secret dockerhub-secret --ignore-not-found=true

    # Delete ImageStreams and BuildConfigs
    print_status "Deleting build resources..."
    oc delete imagestream ospo-events-app --ignore-not-found=true
    oc delete buildconfig ospo-events-app --ignore-not-found=true

    # Explicitly preserve PVCs - DO NOT DELETE THESE
    print_status "âœ… PRESERVING PersistentVolumeClaims (data safe):"
    print_status "   - postgres-pvc (Keycloak users + Event data)"
    print_status "   - minio-pvc (File uploads)"
    print_status "   - ospo-uploads-pvc (Application uploads)"

    # Wait for pods to be fully deleted
    print_status "Waiting for pods to be fully deleted..."
    sleep 10

    # Verify PVCs are still there
    print_status "Verifying data preservation..."
    if oc get pvc postgres-pvc >/dev/null 2>&1; then
        print_success "âœ… PostgreSQL PVC preserved (Keycloak users + Events data safe)"
    else
        print_error "âŒ PostgreSQL PVC missing! Data may be lost!"
    fi

    if oc get pvc minio-pvc >/dev/null 2>&1; then
        print_success "âœ… MinIO PVC preserved (File uploads safe)"
    else
        print_error "âŒ MinIO PVC missing! File uploads may be lost!"
    fi

    if oc get pvc ospo-uploads-pvc >/dev/null 2>&1; then
        print_success "âœ… App uploads PVC preserved (Application uploads safe)"
    else
        print_error "âŒ App uploads PVC missing! Application uploads may be lost!"
    fi

    print_success "ğŸ‰ All pods deleted successfully!"
    print_status "ğŸ“‹ Summary:"
    echo "   âœ… All deployments, services, and routes removed"
    echo "   âœ… All user data preserved in PostgreSQL"
    echo "   âœ… All event data preserved in PostgreSQL"
    echo "   âœ… All file uploads preserved in MinIO"
    echo "   âœ… All application uploads preserved"
    echo ""
    print_status "ğŸ’¡ To redeploy, run:"
    echo "   ./deploy.sh --${ENVIRONMENT}"
    echo ""
    print_warning "âš ï¸  Note: You may need to recreate users in Keycloak if this was the first deployment"
}

# Function to create a complete backup of all data
backup_all_data() {
    if [[ -z "$ENVIRONMENT" ]]; then
        print_error "ğŸš¨ Environment must be specified for backup operation. Use --dev or --prod"
        show_usage
        exit 1
    fi

    print_status "ğŸ“¦ Starting complete data backup..."

    # Create backup directory with timestamp
    BACKUP_TIMESTAMP=$(date +"%Y%m%d_%H%M%S")
    BACKUP_DIR="backup/${ENVIRONMENT}_backup_${BACKUP_TIMESTAMP}"

    print_status "Creating backup directory: $BACKUP_DIR"
    mkdir -p "$BACKUP_DIR"

    # Check if PostgreSQL pod is running
    if ! oc get pod -l app=postgres --field-selector=status.phase=Running | grep -q postgres; then
        print_error "âŒ PostgreSQL pod is not running. Cannot backup database data."
        print_status "Attempting to start PostgreSQL..."
        oc scale deployment postgres --replicas=1
        print_status "Waiting for PostgreSQL to be ready..."
        sleep 30
    fi

    # Backup PostgreSQL database
    print_status "ğŸ“Š Backing up PostgreSQL database..."
    if oc get pod -l app=postgres --field-selector=status.phase=Running | grep -q postgres; then
        POSTGRES_POD=$(oc get pod -l app=postgres --field-selector=status.phase=Running -o jsonpath='{.items[0].metadata.name}')

        # Backup the main events database
        oc exec $POSTGRES_POD -- pg_dump -U ${POSTGRES_USER} -d ${POSTGRES_DB} > "$BACKUP_DIR/events_database.sql"

        # Backup the Keycloak database
        oc exec $POSTGRES_POD -- pg_dump -U ${POSTGRES_USER} -d ${KEYCLOAK_DB_NAME} > "$BACKUP_DIR/keycloak_database.sql"

        print_success "âœ… PostgreSQL databases backed up"
    else
        print_error "âŒ Could not backup PostgreSQL - pod not running"
    fi

    # Backup MinIO data
    print_status "ğŸ“ Backing up MinIO file uploads..."
    if oc get pod -l app=minio --field-selector=status.phase=Running | grep -q minio; then
        MINIO_POD=$(oc get pod -l app=minio --field-selector=status.phase=Running -o jsonpath='{.items[0].metadata.name}')

        # Create MinIO backup directory
        mkdir -p "$BACKUP_DIR/minio_backup"

        # Try to use oc rsync first
        if oc rsync $MINIO_POD:/data "$BACKUP_DIR/minio_backup/" --no-perms=true 2>/dev/null; then
            print_success "âœ… MinIO file uploads backed up via rsync"
        else
            print_warning "âš ï¸  MinIO rsync failed, trying alternative methods..."

            # Alternative 1: Try to copy individual files using oc cp
            print_status "Trying file-by-file copy method..."
            if oc exec $MINIO_POD -- find /data -type f -name "*" 2>/dev/null | head -10 > /dev/null; then
                # Get list of files and copy them individually
                oc exec $MINIO_POD -- find /data -type f 2>/dev/null | while read file; do
                    if [[ -n "$file" ]]; then
                        # Create directory structure
                        dir=$(dirname "$file")
                        mkdir -p "$BACKUP_DIR/minio_backup$dir"
                        # Copy file
                        oc cp "$MINIO_POD:$file" "$BACKUP_DIR/minio_backup$file" 2>/dev/null || true
                    fi
                done
                print_success "âœ… MinIO file uploads backed up via file copy"
            else
                # Alternative 2: Use MinIO client to export data
                print_status "Trying MinIO client export method..."
                if oc exec $MINIO_POD -- which mc >/dev/null 2>&1; then
                    oc exec $MINIO_POD -- mc mirror /data /tmp/backup 2>/dev/null || true
                    oc cp "$MINIO_POD:/tmp/backup" "$BACKUP_DIR/minio_backup/" 2>/dev/null || true
                    oc exec $MINIO_POD -- rm -rf /tmp/backup 2>/dev/null || true
                    print_success "âœ… MinIO file uploads backed up via MinIO client"
                else
                    print_warning "âš ï¸  MinIO backup skipped - no suitable method available"
                    print_warning "   MinIO container lacks rsync, tar, and MinIO client"
                    print_warning "   Consider upgrading MinIO image or implementing custom backup"
                fi
            fi
        fi
    else
        print_error "âŒ Could not backup MinIO - pod not running"
    fi

    # Backup application uploads
    print_status "ğŸ“ Backing up application uploads..."
    if oc get pod -l app=ospo-app --field-selector=status.phase=Running | grep -q ospo-app; then
        APP_POD=$(oc get pod -l app=ospo-app --field-selector=status.phase=Running -o jsonpath='{.items[0].metadata.name}')

        # Create app uploads backup directory
        mkdir -p "$BACKUP_DIR/app_uploads_backup"

        # Try to use oc rsync first
        if oc rsync $APP_POD:/app/uploads "$BACKUP_DIR/app_uploads_backup/" --no-perms=true 2>/dev/null; then
            print_success "âœ… Application uploads backed up via rsync"
        else
            print_warning "âš ï¸  App uploads rsync failed, trying alternative methods..."

            # Alternative 1: Try to copy individual files using oc cp
            print_status "Trying file-by-file copy method..."
            if oc exec $APP_POD -- find /app/uploads -type f -name "*" 2>/dev/null | head -10 > /dev/null; then
                # Get list of files and copy them individually
                oc exec $APP_POD -- find /app/uploads -type f 2>/dev/null | while read file; do
                    if [[ -n "$file" ]]; then
                        # Create directory structure
                        dir=$(dirname "$file")
                        mkdir -p "$BACKUP_DIR/app_uploads_backup$dir"
                        # Copy file
                        oc cp "$APP_POD:$file" "$BACKUP_DIR/app_uploads_backup$file" 2>/dev/null || true
                    fi
                done
                print_success "âœ… Application uploads backed up via file copy"
            else
                # Alternative 2: Try tar if available
                print_status "Trying tar method..."
                if oc exec $APP_POD -- which tar >/dev/null 2>&1; then
                    oc exec $APP_POD -- tar -czf /tmp/app_uploads_backup.tar.gz -C /app/uploads .
                    oc cp $APP_POD:/tmp/app_uploads_backup.tar.gz "$BACKUP_DIR/app_uploads_backup.tar.gz"
                    oc exec $APP_POD -- rm /tmp/app_uploads_backup.tar.gz
                    print_success "âœ… Application uploads backed up via tar"
                else
                    print_warning "âš ï¸  App uploads backup skipped - no suitable method available"
                    print_warning "   App container lacks rsync and tar"
                fi
            fi
        fi
    else
        print_error "âŒ Could not backup application uploads - pod not running"
    fi

    # Create backup metadata
    print_status "ğŸ“‹ Creating backup metadata..."
    cat > "$BACKUP_DIR/backup_metadata.txt" <<EOF
Events Manager Backup
=========================
Backup Date: $(date)
Environment: $ENVIRONMENT
Namespace: $NAMESPACE
Database: $POSTGRES_DB
Keycloak Database: $KEYCLOAK_DB_NAME

Contents:
- events_database.sql: Main application database
- keycloak_database.sql: Keycloak user and authentication data
- minio_backup/: File uploads from MinIO
- app_uploads_backup/: Application uploads
- backup_metadata.txt: This file

Restore Command:
./deploy.sh --restore -f $BACKUP_DIR
EOF

    print_success "ğŸ‰ Backup completed successfully!"
    print_status "ğŸ“‹ Backup Summary:"
    echo "   ğŸ“ Backup Location: $BACKUP_DIR"
    echo "   ğŸ“Š Events Database: $(du -h "$BACKUP_DIR/events_database.sql" 2>/dev/null | cut -f1 || echo "N/A")"
    echo "   ğŸ‘¥ Keycloak Database: $(du -h "$BACKUP_DIR/keycloak_database.sql" 2>/dev/null | cut -f1 || echo "N/A")"
    echo "   ğŸ“ MinIO Data: $(du -sh "$BACKUP_DIR/minio_backup" 2>/dev/null | cut -f1 || echo "N/A")"
    echo "   ğŸ“ App Uploads: $(du -sh "$BACKUP_DIR/app_uploads_backup" 2>/dev/null | cut -f1 || echo "N/A")"
    echo ""
    print_status "ğŸ’¡ To restore this backup:"
    echo "   ./deploy.sh --restore -f $BACKUP_DIR"
}

# Function to restore data from backup
restore_from_backup() {
    if [[ -z "$RESTORE_PATH" ]]; then
        print_error "Restore path must be specified with -f option"
        exit 1
    fi

    if [[ ! -d "$RESTORE_PATH" ]]; then
        print_error "Backup directory not found: $RESTORE_PATH"
        exit 1
    fi

    print_warning "âš ï¸  WARNING: This will RESTORE data from backup!"
    print_warning "âš ï¸  This action will:"
    print_warning "   - Restore PostgreSQL databases (events + keycloak)"
    print_warning "   - Restore MinIO file uploads"
    print_warning "   - Restore application uploads"
    print_warning "   - OVERWRITE existing data in the cluster"
    print_warning ""
    print_warning "âš ï¸  CURRENT DATA WILL BE LOST!"
    echo ""

    # Show backup info
    if [[ -f "$RESTORE_PATH/backup_metadata.txt" ]]; then
        print_status "ğŸ“‹ Backup Information:"
        cat "$RESTORE_PATH/backup_metadata.txt"
        echo ""
    fi

    # Require explicit confirmation
    read -p "Are you absolutely sure you want to restore from backup? Type 'RESTORE FROM BACKUP' to confirm: " confirmation

    if [[ "$confirmation" != "RESTORE FROM BACKUP" ]]; then
        print_error "Restore cancelled. You must type 'RESTORE FROM BACKUP' exactly to confirm."
        exit 1
    fi

    print_status "ğŸ”„ Starting data restoration..."

    # Ensure PostgreSQL is running
    print_status "Ensuring PostgreSQL is running..."
    oc scale deployment postgres --replicas=1
    sleep 10

    # Wait for PostgreSQL to be ready
    print_status "Waiting for PostgreSQL to be ready..."
    until oc get pod -l app=postgres --field-selector=status.phase=Running | grep -q postgres; do
        print_status "Waiting for PostgreSQL pod..."
        sleep 5
    done

    POSTGRES_POD=$(oc get pod -l app=postgres --field-selector=status.phase=Running -o jsonpath='{.items[0].metadata.name}')

    # Restore PostgreSQL databases
    print_status "ğŸ“Š Restoring PostgreSQL databases..."

    # Restore events database
    if [[ -f "$RESTORE_PATH/events_database.sql" ]]; then
        print_status "Restoring events database..."
        oc exec -i $POSTGRES_POD -- psql -U ${POSTGRES_USER} -d ${POSTGRES_DB} < "$RESTORE_PATH/events_database.sql"
        print_success "âœ… Events database restored"
    else
        print_error "âŒ Events database backup not found"
    fi

    # Restore Keycloak database
    if [[ -f "$RESTORE_PATH/keycloak_database.sql" ]]; then
        print_status "Restoring Keycloak database..."
        oc exec -i $POSTGRES_POD -- psql -U ${POSTGRES_USER} -d ${KEYCLOAK_DB_NAME} < "$RESTORE_PATH/keycloak_database.sql"
        print_success "âœ… Keycloak database restored"
    else
        print_error "âŒ Keycloak database backup not found"
    fi

    # Restore MinIO data
    print_status "ğŸ“ Restoring MinIO file uploads..."
    oc scale deployment minio --replicas=1
    sleep 10

    until oc get pod -l app=minio --field-selector=status.phase=Running | grep -q minio; do
        print_status "Waiting for MinIO pod..."
        sleep 5
    done

    MINIO_POD=$(oc get pod -l app=minio --field-selector=status.phase=Running -o jsonpath='{.items[0].metadata.name}')

    if [[ -d "$RESTORE_PATH/minio_backup" ]]; then
        if oc rsync "$RESTORE_PATH/minio_backup/" $MINIO_POD:/data --no-perms=true 2>/dev/null; then
            print_success "âœ… MinIO file uploads restored via rsync"
        else
            print_warning "âš ï¸  MinIO rsync failed, trying alternative methods..."

            # Try file-by-file restore
            if find "$RESTORE_PATH/minio_backup" -type f | head -1 >/dev/null 2>&1; then
                print_status "Trying file-by-file restore..."
                find "$RESTORE_PATH/minio_backup" -type f | while read file; do
                    if [[ -n "$file" ]]; then
                        # Calculate relative path
                        rel_path="${file#$RESTORE_PATH/minio_backup}"
                        oc cp "$file" "$MINIO_POD:/data$rel_path" 2>/dev/null || true
                    fi
                done
                print_success "âœ… MinIO file uploads restored via file copy"
            else
                print_warning "âš ï¸  MinIO restore skipped - no files found"
            fi
        fi
    elif [[ -f "$RESTORE_PATH/minio_backup.tar.gz" ]]; then
        print_status "Restoring MinIO from tar archive..."
        oc cp "$RESTORE_PATH/minio_backup.tar.gz" $MINIO_POD:/tmp/
        oc exec $MINIO_POD -- tar -xzf /tmp/minio_backup.tar.gz -C /data
        oc exec $MINIO_POD -- rm /tmp/minio_backup.tar.gz
        print_success "âœ… MinIO file uploads restored from tar"
    else
        print_error "âŒ MinIO backup directory or tar file not found"
    fi

    # Restore application uploads
    print_status "ğŸ“ Restoring application uploads..."
    oc scale deployment ospo-app --replicas=1
    sleep 10

    until oc get pod -l app=ospo-app --field-selector=status.phase=Running | grep -q ospo-app; do
        print_status "Waiting for application pod..."
        sleep 5
    done

    APP_POD=$(oc get pod -l app=ospo-app --field-selector=status.phase=Running -o jsonpath='{.items[0].metadata.name}')

    if [[ -d "$RESTORE_PATH/app_uploads_backup" ]]; then
        if oc rsync "$RESTORE_PATH/app_uploads_backup/" $APP_POD:/app/uploads --no-perms=true 2>/dev/null; then
            print_success "âœ… Application uploads restored via rsync"
        else
            print_warning "âš ï¸  App uploads rsync failed, trying alternative methods..."

            # Try file-by-file restore
            if find "$RESTORE_PATH/app_uploads_backup" -type f | head -1 >/dev/null 2>&1; then
                print_status "Trying file-by-file restore..."
                find "$RESTORE_PATH/app_uploads_backup" -type f | while read file; do
                    if [[ -n "$file" ]]; then
                        # Calculate relative path
                        rel_path="${file#$RESTORE_PATH/app_uploads_backup}"
                        oc cp "$file" "$APP_POD:/app/uploads$rel_path" 2>/dev/null || true
                    fi
                done
                print_success "âœ… Application uploads restored via file copy"
            else
                print_warning "âš ï¸  App uploads restore skipped - no files found"
            fi
        fi
    elif [[ -f "$RESTORE_PATH/app_uploads_backup.tar.gz" ]]; then
        print_status "Restoring app uploads from tar archive..."
        oc cp "$RESTORE_PATH/app_uploads_backup.tar.gz" $APP_POD:/tmp/
        oc exec $APP_POD -- tar -xzf /tmp/app_uploads_backup.tar.gz -C /app/uploads
        oc exec $APP_POD -- rm /tmp/app_uploads_backup.tar.gz
        print_success "âœ… Application uploads restored from tar"
    else
        print_error "âŒ Application uploads backup directory or tar file not found"
    fi

    print_success "ğŸ‰ Data restoration completed successfully!"
    print_status "ğŸ“‹ Restore Summary:"
    echo "   âœ… Events database restored"
    echo "   âœ… Keycloak database restored"
    echo "   âœ… MinIO file uploads restored"
    echo "   âœ… Application uploads restored"
    echo ""
    print_status "ğŸ’¡ You may need to restart services for changes to take effect"
}

# Function to completely destroy all data
destroy_all_data() {
    if [[ -z "$ENVIRONMENT" ]]; then
        print_error "Environment must be specified for destroy operation. Use --dev or --prod"
        show_usage
        exit 1
    fi

    print_error "ğŸ’€ CATASTROPHIC DESTRUCTION WARNING ğŸ’€"
    print_error "ğŸ’€ THIS WILL PERMANENTLY DESTROY ALL DATA ğŸ’€"
    print_error ""
    print_error "âš ï¸  THIS ACTION WILL:"
    print_error "   - Delete ALL pods in the cluster"
    print_error "   - Delete ALL PersistentVolumeClaims (ALL DATA WILL BE LOST)"
    print_error "   - Delete ALL deployments, services, and routes"
    print_error "   - Delete ALL configuration and secrets"
    print_error "   - Make ALL user data, events, and uploads IRRETRIEVABLE"
    print_error ""
    print_error "ğŸ’€ DATA THAT WILL BE DESTROYED FOREVER:"
    print_error "   - All Keycloak users and authentication data"
    print_error "   - All events and event management data"
    print_error "   - All file uploads and attachments"
    print_error "   - All application configuration and settings"
    print_error ""
    print_error "ğŸ’€ THIS CANNOT BE UNDONE! ğŸ’€"
    print_error ""
    print_error "âš ï¸  YOU SHOULD BACKUP THE CLUSTER FIRST:"
    print_error "   ./deploy.sh --backup"
    echo ""

    # Multiple confirmation prompts
    print_warning "First confirmation: Type 'I UNDERSTAND DATA WILL BE LOST'"
    read -p "Confirmation: " confirmation1

    if [[ "$confirmation1" != "I UNDERSTAND DATA WILL BE LOST" ]]; then
        print_error "Destruction cancelled."
        exit 1
    fi

    print_warning "Second confirmation: Type 'DESTROY ALL DATA PERMANENTLY'"
    read -p "Confirmation: " confirmation2

    if [[ "$confirmation2" != "DESTROY ALL DATA PERMANENTLY" ]]; then
        print_error "Destruction cancelled."
        exit 1
    fi

    print_warning "Final confirmation: Type 'FINAL CONFIRMATION - DESTROY EVERYTHING'"
    read -p "Final confirmation: " confirmation3

    if [[ "$confirmation3" != "FINAL CONFIRMATION - DESTROY EVERYTHING" ]]; then
        print_error "Destruction cancelled."
        exit 1
    fi

    print_error "ğŸ’€ PROCEEDING WITH CATASTROPHIC DESTRUCTION ğŸ’€"

    # Delete all deployments first
    print_status "Deleting all deployments..."
    oc delete deployment --all --ignore-not-found=true

    # Delete all services
    print_status "Deleting all services..."
    oc delete service --all --ignore-not-found=true

    # Delete all routes
    print_status "Deleting all routes..."
    oc delete route --all --ignore-not-found=true

    # Delete all configmaps
    print_status "Deleting all configmaps..."
    oc delete configmap --all --ignore-not-found=true

    # Delete all secrets
    print_status "Deleting all secrets..."
    oc delete secret --all --ignore-not-found=true

    # Delete all ImageStreams and BuildConfigs
    print_status "Deleting all build resources..."
    oc delete imagestream --all --ignore-not-found=true
    oc delete buildconfig --all --ignore-not-found=true

    # CATASTROPHIC: Delete all PVCs (THIS DESTROYS ALL DATA)
    print_error "ğŸ’€ DESTROYING ALL PERSISTENT VOLUME CLAIMS ğŸ’€"
    print_error "ğŸ’€ ALL DATA WILL BE PERMANENTLY LOST ğŸ’€"
    oc delete pvc --all --ignore-not-found=true

    print_error "ğŸ’€ CATASTROPHIC DESTRUCTION COMPLETED ğŸ’€"
    print_error "ğŸ’€ ALL DATA HAS BEEN PERMANENTLY DESTROYED ğŸ’€"
    print_error ""
    print_error "ğŸ“‹ What was destroyed:"
    print_error "   ğŸ’€ All pods and deployments"
    print_error "   ğŸ’€ All services and routes"
    print_error "   ğŸ’€ All configuration and secrets"
    print_error "   ğŸ’€ All PersistentVolumeClaims"
    print_error "   ğŸ’€ ALL USER DATA (irretrievable)"
    print_error "   ğŸ’€ ALL EVENT DATA (irretrievable)"
    print_error "   ğŸ’€ ALL FILE UPLOADS (irretrievable)"
    print_error ""
    print_error "âš ï¸  To start fresh, run: ./deploy.sh --${ENVIRONMENT}"
}

# Function to delete local KIND cluster
delete_local_cluster() {
    # Check if kind is installed
    if ! command -v kind &>/dev/null; then
        print_error "kind is required but not installed!"
        echo "Installation instructions:"
        echo "  brew install kind"
        exit 1
    fi

    print_warning "âš ï¸  WARNING: This will delete the local KIND cluster!"
    print_warning "âš ï¸  This action will:"
    print_warning "   - Delete the entire 'ospo-local' KIND cluster"
    print_warning "   - Remove all data (PostgreSQL, Keycloak, MinIO)"
    print_warning "   - Remove all pods, services, and persistent volumes"
    print_warning ""
    print_warning "âš ï¸  ALL LOCAL DEVELOPMENT DATA WILL BE LOST!"
    echo ""

    # Check if cluster exists
    if ! kind get clusters 2>/dev/null | grep -q "^ospo-local$"; then
        print_warning "KIND cluster 'ospo-local' does not exist"
        print_info "Nothing to delete"
        exit 0
    fi

    # Require explicit confirmation
    read -p "Are you sure you want to delete the local KIND cluster? Type 'DELETE LOCAL CLUSTER' to confirm: " confirmation

    if [[ "$confirmation" != "DELETE LOCAL CLUSTER" ]]; then
        print_error "Deletion cancelled. You must type 'DELETE LOCAL CLUSTER' exactly to confirm."
        exit 1
    fi

    print_status "ğŸ—‘ï¸  Deleting local KIND cluster 'ospo-local'..."

    # Delete the KIND cluster
    KIND_EXPERIMENTAL_PROVIDER=podman kind delete cluster --name ospo-local

    if [ $? -eq 0 ]; then
        print_success "âœ… Local KIND cluster deleted successfully!"
        echo ""
        print_info "ğŸ“‹ What was deleted:"
        echo "   - KIND cluster 'ospo-local'"
        echo "   - All pods (PostgreSQL, Keycloak, MinIO)"
        echo "   - All persistent volumes and data"
        echo "   - All services and network configuration"
        echo ""
        print_info "ğŸ’¡ To recreate the local development environment:"
        echo "   ./deploy.sh --local"
    else
        print_error "âŒ Failed to delete KIND cluster"
        exit 1
    fi
}

# Main deployment function
main() {
    print_status "ğŸš€ Starting deployment process..."

    # SAFETY CHECK: Ensure this script is only used for deployments
    if [[ "$DELETE" != "true" && "$BACKUP" != "true" && "$RESTORE" != "true" && "$DESTROY" != "true" ]]; then
        print_status "ğŸ”’ SAFETY MODE ENABLED - This script will NOT perform destructive operations"
        print_status "ğŸ”’ All data-preserving operations only"
    fi

    # Handle backup operation
    if [[ "$BACKUP" == "true" ]]; then
        backup_all_data
        exit 0
    fi

    # Handle restore operation
    if [[ "$RESTORE" == "true" ]]; then
        restore_from_backup
        exit 0
    fi

    # Handle destroy operation
    if [[ "$DESTROY" == "true" ]]; then
        destroy_all_data
        exit 0
    fi

    # Handle delete local cluster operation
    if [[ "$DELETE_LOCAL" == "true" ]]; then
        delete_local_cluster
        exit 0
    fi

    # Handle delete operation
    if [[ "$DELETE" == "true" ]]; then
        if [[ -z "$ENVIRONMENT" ]]; then
            print_error "Environment must be specified for delete operation. Use --dev or --prod"
            show_usage
            exit 1
        fi
        print_warning "âš ï¸  WARNING: DELETE operation requested!"
        print_warning "âš ï¸  This will delete ALL pods in the $ENVIRONMENT environment!"
        delete_all_pods
        exit 0
    fi


    # Handle local KIND cluster deployment
    if [[ "$ENVIRONMENT" == "local" ]]; then
        # Deploy individual components if flags are set
        if [[ "$POSTGRES" == "true" ]]; then
            deploy_postgres_local
        fi

        if [[ "$KEYCLOAK" == "true" ]]; then
            deploy_keycloak_local
        fi

        if [[ "$MINIO" == "true" ]]; then
            deploy_minio_local
        fi

        # If specific components were deployed, show summary and exit
        if [[ "$POSTGRES" == "true" || "$KEYCLOAK" == "true" || "$MINIO" == "true" ]]; then
            print_success "ğŸ‰ Deployment completed successfully!"
            echo ""
            print_status "ğŸ“‹ Deployment Summary:"
            if [[ "$POSTGRES" == "true" ]]; then
                echo "   âœ… PostgreSQL Deployed"
            fi
            if [[ "$KEYCLOAK" == "true" ]]; then
                echo "   âœ… Keycloak Deployed"
            fi
            if [[ "$MINIO" == "true" ]]; then
                echo "   âœ… MinIO Deployed"
            fi
            echo "   Environment: $ENVIRONMENT"
            echo "   Namespace: $NAMESPACE"
            echo ""
            print_info "Service Access URLs (from localhost):"
            echo "  PostgreSQL:     localhost:5432 (ospo_user/ospo_password)"
            echo "  Keycloak:       http://localhost:8080/auth (admin/admin)"
            echo "  MinIO API:      http://localhost:9000 (minioadmin/minioadmin)"
            echo "  MinIO Console:  http://localhost:9001"
            echo ""
            print_status "ğŸ” Checking deployment status..."
            kubectl get pods -n "$NAMESPACE"
            echo ""
            print_info "ğŸš€ To run application locally with hot reload:"
            echo "  npm run dev:local"
            echo ""
            print_info "Application will run on your machine and connect to services in KIND."
            exit 0
        fi

        # If no specific components were requested, deploy all
        print_status "ğŸš€ Deploying all services to local KIND cluster..."
        deploy_postgres_local
        deploy_keycloak_local
        deploy_minio_local

        print_success "ğŸ‰ All services deployed successfully!"
        echo ""
        print_status "ğŸ“‹ Deployment Summary:"
        echo "   Environment: $ENVIRONMENT"
        echo "   Namespace: $NAMESPACE"
        echo "   âœ… PostgreSQL Deployed to KIND"
        echo "   âœ… Keycloak Deployed to KIND"
        echo "   âœ… MinIO Deployed to KIND"
        echo ""
        print_info "Service Access URLs (from localhost):"
        echo "  PostgreSQL:     localhost:5432 (ospo_user/ospo_password)"
        echo "  Keycloak:       http://localhost:8080/auth (admin/admin)"
        echo "  MinIO API:      http://localhost:9000 (minioadmin/minioadmin)"
        echo "  MinIO Console:  http://localhost:9001"
        echo ""
        print_status "ğŸ” Checking deployment status..."
        kubectl get pods -n "$NAMESPACE"
        echo ""
        print_warning "âš¡ IMPORTANT: Services are deployed, but application is NOT deployed yet."
        print_info "ğŸš€ Next steps to run application locally with hot reload:"
        echo "  1. Push database schema:    npm run db:push:local"
        echo "  2. Run application locally:  npm run dev:local"
        echo ""
        print_success "âœ¨ Local development stack is ready! Run 'npm run dev:local' to start developing."
        exit 0
    fi

    # Handle GKE/EKS deployment
    if [[ "$ENVIRONMENT" == "gke" || "$ENVIRONMENT" == "eks" ]]; then
        # Deploy postgres if flag is set
        if [[ "$POSTGRES" == "true" ]]; then
            print_status "ğŸš€ Deploying PostgreSQL..."
            $CLI_CMD scale deployment postgres --replicas=0 -n "${NAMESPACE}" || true
            sleep 5
            deploy_postgres
            sleep 5
            $CLI_CMD scale deployment postgres --replicas=1 -n "${NAMESPACE}"
            print_success "ğŸ‰ PostgreSQL deployed successfully!"
        fi

        # Deploy keycloak if flag is set
        if [[ "$KEYCLOAK" == "true" ]]; then
            print_status "ğŸš€ Deploying Keycloak..."
            kc_running=$($CLI_CMD get pods -n "${NAMESPACE}" | grep keycloak | wc -l)
            if [[ $kc_running -eq 0 ]]; then
                print_status "ğŸš€ Keycloak not running, deploying..."
                deploy_keycloak
                sleep 5
                print_success "ğŸ‰ Keycloak deployed successfully!"
            else
                $CLI_CMD scale deployment keycloak --replicas=0 -n "${NAMESPACE}"
                sleep 5
                deploy_keycloak
                sleep 5
                $CLI_CMD scale deployment keycloak --replicas=1 -n "${NAMESPACE}"
                print_success "ğŸ‰ Keycloak deployed successfully!"
            fi
        fi

        # Deploy minio if flag is set
        if [[ "$MINIO" == "true" ]]; then
            print_status "ğŸš€ Deploying MinIO..."
            deploy_minio
            print_success "ğŸ‰ MinIO deployed successfully!"
        fi

        # Deploy application if flag is set
        if [[ "$APP" == "true" ]]; then
            print_status "ğŸš€ Deploying the application..."
            local current_version=$(get_package_version)
            print_status "ğŸ” Current version in package.json: $current_version"

            # For GKE/EKS, always build unless we implement version checking for external registries
            deploy_app
            $CLI_CMD scale deployment ospo-app --replicas=0 -n "${NAMESPACE}" || true
            sleep 5
            $CLI_CMD scale deployment ospo-app --replicas=1 -n "${NAMESPACE}"
            print_success "ğŸ‰ Application deployed successfully!"
        fi

        # Create ingress if routes flag is set or if deploying app
        if [[ "$ROUTES" == "true" || "$APP" == "true" ]]; then
            create_routes
            print_success "ğŸ‰ Ingress created successfully!"
        fi

        # Show summary
        if [[ "$APP" == "true" || "$KEYCLOAK" == "true" || "$POSTGRES" == "true" || "$MINIO" == "true" ]]; then
            print_success "ğŸ‰ Deployment completed successfully!"
            echo ""
            print_status "ğŸ“‹ Deployment Summary:"
            if [[ "$APP" == "true" ]]; then
                echo "   âœ… Application Deployed"
            fi
            if [[ "$KEYCLOAK" == "true" ]]; then
                echo "   âœ… Keycloak Deployed"
            fi
            if [[ "$POSTGRES" == "true" ]]; then
                echo "   âœ… PostgreSQL Deployed"
            fi
            if [[ "$MINIO" == "true" ]]; then
                echo "   âœ… MinIO Deployed"
            fi
            echo "   Environment: $ENVIRONMENT"
            echo "   Platform: $PLATFORM"
            echo "   Namespace: $NAMESPACE"
            echo "   Application URL: $APP_URL"
            echo "   Keycloak URL: $KEYCLOAK_URL"
            echo ""
            print_status "ğŸ” Checking deployment status..."
            $CLI_CMD get pods -n "${NAMESPACE}"
            exit 0
        fi

        # Deploy all components in order (default behavior)
        deploy_postgres
        deploy_keycloak
        deploy_minio
        deploy_app
        create_routes

        print_success "ğŸ‰ Deployment completed successfully!"
        echo ""
        print_status "ğŸ“‹ Deployment Summary:"
        echo "   Environment: $ENVIRONMENT"
        echo "   Platform: $PLATFORM"
        echo "   Namespace: $NAMESPACE"
        echo "   Application URL: $APP_URL"
        echo "   Keycloak URL: $KEYCLOAK_URL"
        echo ""
        print_status "ğŸ” Checking deployment status..."
        $CLI_CMD get pods -n "${NAMESPACE}"
        echo ""
        print_success "âœ¨ Events Manager is now deployed and ready!"
        exit 0
    fi

    # Handle OpenShift (dev/prod) deployment
    # Deploy postgres if flag is set
    if [[ "$POSTGRES" == "true" ]]; then
        print_status "ğŸš€ Deploying the postgres pod..."
        oc scale deployment postgres --replicas=0
        sleep 5
        deploy_postgres
        sleep 5
        oc scale deployment postgres --replicas=1
        print_success "ğŸ‰ Postgres deployed successfully!"
    fi

    # Deploy keycloak if flag is set
    if [[ "$KEYCLOAK" == "true" ]]; then
        print_status "ğŸš€ Deploying the keycloak pod..."
        kc_running=$(oc get pods | grep keycloak | wc -l)
        if [[ $kc_running -eq 0 ]]; then
          print_status "ğŸš€ Keycloak not running, deploying the keycloak pod..."
          deploy_keycloak
          sleep 5
          print_success "ğŸ‰ Keycloak deployed successfully!"
        else
          oc scale deployment keycloak --replicas=0
          sleep 5
          deploy_keycloak
          sleep 5
          oc scale deployment keycloak --replicas=1
          print_success "ğŸ‰ Keycloak deployed successfully!"
        fi
    fi

    # Deploy application if flag is set
    if [[ "$APP" == "true" ]]; then
      print_status "ğŸš€ Deploying the application..."
      # Get current version from package.json
      local current_version=$(get_package_version)
      print_status "ğŸ” Current version in package.json: $current_version"

      # Check if build is needed (unless --force is specified)
      if [[ "$FORCE_BUILD" != "true" ]]; then
        local imagestream_name="ospo-events-app"
        latest_tagged_version=$(get_latest_image_version "$imagestream_name")
        print_status "ğŸ” Latest version in registry: $latest_tagged_version"
        if [[ -n "$latest_tagged_version" ]]; then
          print_status "ğŸ” Latest version in registry: $latest_tagged_version"
          if version_greater "$current_version" "$latest_tagged_version"; then
            print_status "Version $current_version > $latest_tagged_version, build needed"
          else
            print_success "Version $current_version <= $latest_tagged_version, skipping build"
            print_success "Use --force flag to force a rebuild"
            return 0
          fi
        else
          print_status "ğŸ” No previous version found in registry, building first version"
        fi
      else
        print_status "Force build requested, skipping version check"
      fi
      deploy_app
      oc scale deployment ospo-app --replicas=0
      sleep 5
      oc scale deployment ospo-app --replicas=1
      print_success "ğŸ‰ Application deployed successfully!"
    fi

    if [[ "$ROUTES" == "true" ]]; then
        create_routes
        print_success "ğŸ‰ Routes created successfully!"
        exit 0
    fi

    if [[ "$APP" == "true" || "$KEYCLOAK" == "true" || "$POSTGRES" == "true" || "$MINIO" == "true" || "$AI" == "true" ]]; then
      print_success "ğŸ‰ Deployment completed successfully!"
      echo ""
      print_status "ğŸ“‹ Deployment Summary:"
      if [[ "$APP" == "true" ]]; then
        echo "   Application Redeployed"
      fi
      if [[ "$KEYCLOAK" == "true" ]]; then
        echo "   Keycloak Redeployed"
      fi
      if [[ "$POSTGRES" == "true" ]]; then
        echo "   PostgreSQL Redeployed"
      fi
      if [[ "$MINIO" == "true" ]]; then
        echo "   MinIO Redeployed"
      fi
      if [[ "$AI" == "true" ]]; then
        echo "   AI Redeployed"
      fi
      echo "   Environment: $ENVIRONMENT"
      echo "   Namespace: $NAMESPACE"
      echo "   Application URL: $APP_URL"
      echo "   Keycloak URL: $KEYCLOAK_URL"
      echo ""
      print_status "ğŸ” Checking deployment status..."
      oc get pods -l app
      exit 0
    fi

    # Deploy all components in order (default behavior for OpenShift)
    create_dockerhub_secret
    deploy_postgres
    deploy_keycloak
    deploy_app
    create_routes
    print_success "ğŸ‰ Deployment completed successfully!"
    echo ""
    print_status "ğŸ“‹ Deployment Summary:"
    echo "   Environment: $ENVIRONMENT"
    echo "   Platform: $PLATFORM"
    echo "   Namespace: $NAMESPACE"
    echo "   Application URL: $APP_URL"
    echo "   Keycloak URL: $KEYCLOAK_URL"
    echo ""
    print_status "ğŸ” Checking deployment status..."
    oc get pods -l app
    echo ""
    print_success "âœ¨ Events Manager is now deployed and ready!"
}

# Run main function
main "$@"
